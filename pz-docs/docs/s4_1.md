## S4.1 - PZ Training Set Maker 

#### Introduction

The Python package [`pz-tsm`](https://github.com/linea-it/pz-tsm) (Training Set Maker for Photo-zs) is inspired by its namesake Training Set Maker pipeline, available on the DES Science Portal ([Gschwend et al., 2018](https://www.sciencedirect.com/science/article/abs/pii/S2213133718300891?via%3Dihub)), but will rely on completely different infrastructure. The package is designed to handle lightweight catalogs of spectroscopic redshifts (spec-z) to be used for the purpose of training and validation of PZ algorithms. 

[`pz-tsm`](https://github.com/linea-it/pz-tsm) will offer useful Python functions to manipulate and visualize these catalogs that are expected to contain the order of hundreds of thousands of objects. It is by no means to be considered an efficient tool to manipulate big data at the user's work environment. Nonetheless, [`pz-tsm`](https://github.com/linea-it/pz-tsm) will take advantage of the administrative functions of the PZ Server to retrieve data and metadata, and the Brazilian IDAC's infrastructure to deal with large datasets. It will provide access to an asynchronous online service that uses IDAC's computing resources to perform combinations of different datasets and cross-matching with the LSST objects catalog. 

#### Data flow

The figure below shows the data flow through a series of steps.


![Sequence of steps for Training Set Maker](tsm_dataflow.png)


-----
#### Forecasted use cases

1. The user retrieves spec-z catalogs from online services using the [`pz-tsm`](https://github.com/linea-it/pz-tsm) as a search interface. [`pz-tsm`](https://github.com/linea-it/pz-tsm) will provide a list of previous spec-z surveys of interest, for which there will be metadata and quality flags conversion already available (previously fed by the person from LIneA staff in charge of data curation). The implementation will use open-source tools such as those available in [Astroquery](https://astroquery.readthedocs.io/en/latest/) ([Ginsburg, Sip≈ëcz, Brasseur, et al 2019](https://ui.adsabs.harvard.edu/abs/2019AJ....157...98G/abstract)) to retrieve public spec-z catalogs. 

2. The user combines different spec-z catalogs into a single table. [`pz-tsm`](https://github.com/linea-it/pz-tsm) will provide a mechanism to perform spatial cross-matching among multiple tables to resolve multiple spec-z measurements for the same galaxies (flexible criteria) and to standardize quality flags from different surveys. 

3. The user retrieves spec-z catalogs from the PZ Server. [`pz-tsm`](https://github.com/linea-it/pz-tsm) will take advantage of the PZ Server's API [`pz-server-lib`](https://github.com/linea-it/pz-server-lib) (see API's documentation [here](https://linea-it.github.io/pz-server-lib/html/index.html)) to access user-generated catalogs hosted by the server. The PZ Server will host a standardized compilation of spec-z with public data available up to date, vetted by LSST DM staff, to be updated periodically by LIneA staff, easy to find (e.g. flagged as "latest"), and containing detailed documentation for citation of the original sources.  

4. The user combines a spec-z table (local or from PZ Server) with photometric data from the LSST Objects Catalog to build a training set for photo-z codes. [`pz-tsm`](https://github.com/linea-it/pz-tsm) will provide a mechanism to submit jobs to perform spatial cross-matching between a spec-z table and the copy of the LSST data hosted in the Brazilian IDAC, using the IDAC's computing resources. The results of the matching will be sent back to the user's local work environment (e.g. the RSP's notebook aspect). 

5. The user split the matched spec-photo catalog into two or more subsamples (for training and validation/test purposes). [`pz-tsm`](https://github.com/linea-it/pz-tsm) will provide a simple method to split the data randomly into a finite number of parts, with proportions defined by the user. Additional methods that follow specific science-driven criteria to define subsamples or that apply some transformation of the data (e.g. weighting or data augmentation) can be added as contributions from the community. 

6. The LSST PZ Commissioning Team uses the [`pz-tsm`](https://github.com/linea-it/pz-tsm) to create standardized training and validation sets to be used in the _Photo-z Validation Cooperative_ and distribute them to the community through the Photo-z Server. The resulting catalogs will be formatted according to the LSST requirements described in the [DMTN-049 - A Roadmap to Photometric Redshifts for the LSST Object Catalog](https://dmtn-049.lsst.io/) (to be defined by LSST Data Management (DM) System Science Team) and contain all the provenance information necessary to be considered reproducible and ready to be uploaded on the PZ Server. 
